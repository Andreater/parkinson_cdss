---
title: "Untitled"
author: "Andrea Termine"
date: "6/1/2022"
output: html_document
editor_options: 
  markdown: 
    wrap: 72
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r config}
# plant a seed
set.seed(12345)

# Path to config
config = yaml::read_yaml(file = "../config/config r.yaml", eval.expr=TRUE)

# Paths
data.path       = file.path(config$exp$parent, config$file_05$count_dir)
rna.meta.path   = file.path(config$exp$parent, config$file_05$rna_meta_dir)
lcf.out         = config$file_05$lcf_out
udf.path        = file.path(config$exp$parent, config$file_05$udf_dir)
```

```{r libraries, message=FALSE, warning=FALSE, include=FALSE}
# Import custom functions
source(file.path(udf_dir, udf_name))

## Required Packages
pkg = c("tidyverse", "openxlsx", "vroom", "data.table", "patchwork", "readxl", "yaml", "fst")

## Now load or install & load all // Cran version
load_packages(pkgs = pkg)
# cat("Libraries Imported")
rm(pkg,p)
```
# AIM

01 - Explore the cohort data 
02 - Update the experimental cohort 03
03 - Apply Low count filtering

```{r import RNA seq metadata}
rna_seq_metadata = readRDS(file.path(rna.meta.path, config$file_05$rna_meta_name))
rna_seq_metadata %>% head()
```

## Define the experimental cohort

Our first goal is to selected the files belonging to the PD analytic cohort at baseline. The first step is to understand how many files we got regardless of the time-point.

```{r Inspect the cohort composition}
rna_seq_metadata$Cohort   %>% as.factor() %>% levels()
rna_seq_metadata$Subgroup %>% as.factor() %>% levels()

# How many files x cohorts and subgroups?
# Here we are not considering time
rna_seq_metadata %>% 
  xtabs(~ Cohort + Subgroup, data = ., na.action = na.pass)
```

Below a summary plot of the Cohorts *(A)* and Parkinson's Disease subgroups *(B)* in time. As we can see genetic cohorts subject seems to die or drop earlier than sporadic subjects.

```{r inspect the metadata, fig.height= 5, fig.width=9}
pl1 = rna_seq_metadata %>% 
  group_by(Cohort, CLINICAL_EVENT) %>%
  tally() %>% 
  ggplot() +
  aes(x    = CLINICAL_EVENT,
      y    = n,
      fill = Cohort) +
  geom_col(position = "dodge") +
  geom_text(aes(label = n),
            colour = "white",
            size = 3,
            vjust = 1.5,
            position = position_dodge(.9)) +
  labs(x = "Clinical Event")

pl2 =  rna_seq_metadata %>% 
  filter(Cohort == "Parkinson's Disease") %>% 
  group_by(Subgroup, CLINICAL_EVENT) %>% 
  tally() %>% 
  ggplot() +
  aes(x    = CLINICAL_EVENT,
      y    = n,
      fill = Subgroup) +
  geom_col(position = "dodge") +
  geom_text(aes(label = n),
            colour = "white",
            size = 3,
            vjust = 1.5,
            position = position_dodge(.9)) +
  labs(x = "Clinical Event")

# Custom tweakead the fig. sizes of the chunk 
# Please pay attention when you export with ggsave
pl1 + pl2 + plot_layout(ncol = 2, guides = "collect") + plot_annotation(tag_levels = "A")
```

### Update the experimental cohort

We decided to use genetic and sporadic subjects together and we will exclude the prodromal cohort rn. This way we can see if they're really
different based on gene expression or if this split is more representative of a disease's intensity modulation due to the genetic variants. **All of the starting file must come from BL**

## Import the data

### Define the paths and import parameters

```{r}
# PD paths ----
pd_paths = rna_seq_metadata %>% 
  filter(Cohort == "Parkinson's Disease" & CLINICAL_EVENT == "BL") %>% 
  .$path

# HC paths ----
hc_paths = rna_seq_metadata %>% 
  filter(Cohort == "Healthy Control" & CLINICAL_EVENT == "BL") %>% 
  .$path
```

### Test drive import

The fastest way to import a single file is using vroom.But how is composed a RNA-seq file from PPMI? Let's inspect it

```{r example import}
# Benchmark vroom vs data table in one file reading ----
tictoc::tic()
try = vroom(file = pd_paths[1],
            delim = NULL, # autoguess it
            comment = "#",
            # col_names = c("Geneid", "Chr", "Start", "End", "Strand", "Length", "Count"),
            num_threads = 20)
tictoc::toc()

# tictoc::tic()
# try = read.table(file = pd_paths[1],
#                  header = TRUE,
#                  comment.char = "#")
# tictoc::toc()

try %>% head()
```

### Explore the RNA seq file

The RNA-seq file has 7 columns. The last one contains the counts but it is always coded as the original path of the file. It means that changes
for each file and this issue needs to be addressed during the import.

The raw sequence image files from the Illumina NovaSeq6000 in the form of bcl are converted to the fastq format using bcltofastq v1.8.4. Reads
were aligned to the GChr38p12 and long RNA was annotated using the GENCODE v29. Alignment was carried out using STAR aligner 2.6.1d, while Salmon v0.11.3 was used for quantification. Counts were generated using featureCounts v1.6.3.

No additional preprocessing was carried out by
[ITG\@USC](mailto:ITG@USC){.email}.

Sources:
- "E:\ppmi\data\genetic\_data\RNA\_seq\README"
- [featurecounts on galaxy](https://training.galaxyproject.org/training-material/topics/transcriptomics/tutorials/rna-seq-reads-to-counts/tutorial.html)

```{r}
names(try)[-7]
```

## Batch import

```{r message=FALSE, warning=FALSE}
# PD files ----
pd_files        = vector(mode = "list", length = length(pd_paths))
names(pd_files) = rna_seq_metadata$PATNO[rna_seq_metadata$path %in% pd_paths]

pb = txtProgressBar(min = 0, max = length(pd_files), initial = 0) 

# Init windows version
# pb = winProgressBar(title = "title", label = "label", min = 0, max = length(pd_files), initial = 0) 

for (i in 1:length(pd_files)) {
  pd_files[[i]] = vroom(file           = pd_paths[i],
                        delim          = NULL, # autoguess it
                        comment        = "#",
                        col_names      = c("Geneid", "Chr", "Start", "End", "Strand", "Length", "Count"),
                        num_threads    = 20,
                        show_col_types = FALSE)
  
  # Solve the boring problem of the header
  pd_files[[i]] = pd_files[[i]][ -1,]
  
  setTxtProgressBar(pb = pb, value = i)
  
  # Init windows version
  #setWinProgressBar(pb = pb, value = i)
}

close(pb)

# hc files ----
hc_files        = vector(mode = "list", length = length(hc_paths))
names(hc_files) = rna_seq_metadata$PATNO[rna_seq_metadata$path %in% hc_paths]

pb = txtProgressBar(min = 0, max = length(hc_files), initial = 0) 

# Init windows version
# pb = winProgressBar(title = "title", label = "label", min = 0, max = length(hc_files), initial = 0) 

for (i in 1:length(hc_files)) {
  hc_files[[i]] = vroom(file           = hc_paths[i],
                        delim          = NULL, # autoguess it
                        comment        = "#",
                        col_names      = c("Geneid", "Chr", "Start", "End", "Strand", "Length", "Count"),
                        num_threads    = 20,
                        show_col_types = FALSE)
  
  # Solve the boring problem of the header
  hc_files[[i]] = hc_files[[i]][ -1,]
  
  setTxtProgressBar(pb = pb, value = i)
  
  # Init windows version
  #setWinProgressBar(pb = pb, value = i)
}

close(pb)
```

### Check if everybody has the same genes sampled

It seems that every PATNO file has the same number of genes and the same
genes as well.

```{r}
# PD check ----
data.frame(patno   = names(pd_files),
           n_genes = paste(lapply(pd_files, function(x) nrow(x)))
           ) %>% skimr::skim()


pd_genes = Reduce(intersect, lapply(pd_files, function(x) x = x$Geneid))
length(pd_genes)

# hc check ----
data.frame(patno   = names(hc_files),
           n_genes = paste(lapply(hc_files, function(x) nrow(x)))
           ) %>% skimr::skim()


hc_genes = Reduce(intersect, lapply(hc_files, function(x) x = x$Geneid))
length(hc_genes)

# These are the same genes across cohorts
sum(hc_genes == pd_genes)
```

## Export

We should have Genes as rows. So we stack each subject on top of the
other in a long format:

Gene Subject Count 
A1   PD1      1  
A1   PD2      10 
..

Which creates a really long table. This will be heavy so maybe we need to use spark. **757.81 sec (12 minutes)** were needed to export the raw
unfiltered counts.

01 - Add sample name to PD and HC table                              [V]
02 - Reduce to one dataframe for each cohort long format             [V]
03 - Export the raw unfiltered counts for each cohort in long format [V]

```{r}
# 01 ----
for (i in 1:length(pd_files)) {
  pd_files[[i]] = pd_files[[i]] %>% 
    mutate(PATNO = names(pd_files)[i]) %>% 
    relocate(PATNO, .before = everything())
}

pd_files[[i]] %>% names()

for (i in 1:length(hc_files)) {
  hc_files[[i]] = hc_files[[i]] %>% 
    mutate(PATNO = names(hc_files)[i]) %>% 
    relocate(PATNO, .before = everything())
}

hc_files[[i]] %>% names()

# 02 ----
pd_raw_counts = do.call(bind_rows, pd_files)
hc_raw_counts = do.call(bind_rows, hc_files)

## NA check before
pd_raw_counts$Count %>% is.na() %>% sum()
hc_raw_counts$Count %>% is.na() %>% sum()

## Conver the counts to numeric format
pd_raw_counts$Count = as.numeric(pd_raw_counts$Count)
hc_raw_counts$Count = as.numeric(hc_raw_counts$Count)

## NA check after
pd_raw_counts$Count %>% is.na() %>% sum()
hc_raw_counts$Count %>% is.na() %>% sum()

# 03 ----
#tictoc::tic()
#saveRDS(pd_raw_counts, file = file.path(rna.meta.path, "RNA seq", "raw counts", "pd_raw_counts long format.rds"))
#saveRDS(hc_raw_counts, file = file.path(rna.meta.path, "RNA seq", "raw counts", "hc_raw_counts long format.rds"))
#tictoc::toc()
```

## Low count filtering

01 - Set a policy for the Low count filtering LCF [V]
02 - Perform a test drive on the LCF              [V]
03 - Apply LCF to all the counts matrices         [V]
   03.1 - Check if every subject has the same number of genes [V]
04 - Export lcf counts                            [V]
05 - Check common genes between PD and HC         [V]

We are using a two stage LCF filtering where we identify genes below the 15th centile in the 75% of the samples and remove them. In the second stage we remove also the zero variance genes. 12329/58780 **genes were removed** in PD and 11991/58780 **genes were removed** in HC.

**A note about the export**
We started exporting with rds but it is really slow in writing and reading. We studied another solution and here we will use the .fst format.FST relies heavily on multithreading so be aware of the cores' needs.

- [fst site](https://www.fstpackage.org/)
- [benchmark](https://waterdata.usgs.gov/blog/formats/)

```{r}
# 01 Write the LCF function ----
lcf <- function(data, count, id, gene, quant = 0.15) {
  
  # Error 1
  if (is.numeric(data[[count]]) == FALSE) stop("Count vector is not numeric")
  
  # Parameters
  centile = quantile(x = data[[count]], probs = quant)
  
  # LCF filtering
  df = data %>% 
    mutate(index = ifelse(.data[[count]] <= centile, TRUE, FALSE)) %>% 
    group_by(.data[[gene]]) %>%
    # Index1 filters the genes which are = 15th centile in the 75% of the samples 
    # Index_var removes zero variance genes
    mutate(index1    = ifelse(sum(index)/length(unique(.data[[id]] )) >= .75, "drop", "keep"), 
           index_var = ifelse(var(.data[[count]]) == 0, "drop", "keep")) %>% 
    ungroup() %>%
    filter(index1    == "keep",
           index_var == "keep") %>% 
    dplyr::select(-c("index", "index1", "index_var"))
  
  return(df)
}

# 02 - Perfom the test drive ----
test_drive_for_lcf <- read_excel(file.path(lcf.out, "test drive for lcf.xlsx"))

test2 = lcf(data  = test_drive_for_lcf,
            count = "count1",
            id    = "id",
            gene  = "geneid",
            quant = 0.15)

test3 = hc_raw_counts %>% filter(Geneid == "ENSG00000000003.14")

test4 = lcf(data  = test3,
            count = "Count",
            id    = "PATNO",
            gene  = "Geneid",
            quant = 0.15)

# 03 - Perform LCF ----
hc_lcf_counts = lcf(data  = hc_raw_counts,
                    count = "Count",
                    id    = "PATNO",
                    gene  = "Geneid",
                    quant = 0.15)

pd_lcf_counts = lcf(data  = pd_raw_counts,
                    count = "Count",
                    id    = "PATNO",
                    gene  = "Geneid",
                    quant = 0.15)

paste0(length(pd_genes)- length(unique(pd_lcf_counts$Geneid)), "/", length(pd_genes), " genes were removed in PD")

paste0(length(hc_genes)- length(unique(hc_lcf_counts$Geneid)), "/", length(pd_genes), " genes were removed in HC")


## 03.1 Check if every subject has the same number of genes ----
print("PD")
pd_lcf_counts %>% 
  group_by(PATNO) %>% tally() %>% 
  .$n %>% summary()

print("hc")
hc_lcf_counts %>% 
  group_by(PATNO) %>% tally() %>% 
  .$n %>% summary()

# 05 - Check common genes ----
common_hc_pd_genes_after_lcf = intersect(unique(pd_lcf_counts$Geneid), unique(hc_lcf_counts$Geneid))
paste("There are", length(common_hc_pd_genes_after_lcf), "genes in common between PD and HC after lcf")

# 04 - Export LCF counts ----
tictoc::tic()
write_fst(x = pd_lcf_counts, path = file.path(lcf.out, "pd_lcf_counts long format.fst"), compress = 100)
write_fst(x = hc_lcf_counts, path = file.path(lcf.out, "hc_lcf_counts long format.fst"), compress = 100)
tictoc::toc()
```

