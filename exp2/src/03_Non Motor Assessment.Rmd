---
title: "Untitled"
author: "Andrea Termine"
date: "2022-10-28"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r config}
# plant a seed
set.seed(12345)

# Path to config
config = yaml::read_yaml(file = "../config/config r.yaml", eval.expr=TRUE)
```

```{r libraries, message=FALSE, warning=FALSE, include=FALSE}
# Import custom functions
source(config$default$udfPath)
source("udf.R")
source("wide_rm_tester_functions.R")
## Required Packages
pkg = config$default$pkg

## Now load or install & load all // Cran version
load_packages(pkgs = pkg)
# cat("Libraries Imported")
rm(pkg,p)
```

## Data Import

```{r Basic, warning=FALSE}
# Metadata ----
## rna Metadata  ----
meta_rna      = readRDS(config$metadata$rnaMetaPath)
## Analytic Cohort metadata ----
meta_analytic = readRDS(config$metadata$analyticMetaPath)
## PD Labels from M3C ----
pd_labels = read.xlsx(config$metadata$m3cLabelsPath)
pd_labels = pd_labels %>% mutate(label = ifelse(label == 1, "PDC1", "PDC2"))
## Codebook for columns (3 sheets)
codebookNames   = readxl::excel_sheets(path = config$metadata$codebook)
codebook        = vector(mode = "list", length = length(codebookNames))
names(codebook) = codebookNames
for (i in 1:length(codebook)) {codebook[[i]] = read.xlsx(config$metadata$codebook, sheet = i)}
rm(codebookNames)

# Actual Biomedical data ----
## Motor Assessments
non_motor_assessment = batch_csv_import(pathDir = config$nonMotorAssessment$path)

## Basic cohort data
core_set = left_join(meta_rna %>% mutate(PATNO = as.character(PATNO)) %>% 
                       dplyr::select(PATNO, GENDER, Cohort, Subgroup, CLINICAL_EVENT) %>% filter(CLINICAL_EVENT == "BL"),
                     pd_labels, by = "PATNO") %>% 
  mutate(label = ifelse(is.na(label), Cohort, label)) %>% 
  relocate(CLINICAL_EVENT, .after = label) %>% 
  dplyr::select(- CLINICAL_EVENT)

core_set %>% 
  xtabs(~ label, data = .)
```

```{r parameters}
# Select a period spanning from 0 to 2 years every six month
selected_period = c("BL", "V02", "V04", "V05", "V06")
# Select a period spanning from 0 to 2 years every year
selected_period = c("BL", "V04", "V06")

#df    = medication$data[[1]]
gp      = "label"
tp      = "EVENT_ID"
id      = "PATNO"
y       = "value"
REML    = FALSE
```

## Benton

```{r}
# 1 Data Wrangling ----
# check the value column uniques to see if something strange pops ups and address it in the last mutate
benton = non_motor_assessment$benton_judgement_of_line_orientation
benton = benton %>% dplyr::select(-c("INFODT", "REC_ID", "PAG_NAME", "ORIG_ENTRY", "LAST_UPDATE"))
dvs    = c("JLO_TOTRAW","JLO_TOTCALC", "DVS_JLO_MSSAE")

benton = left_join(core_set %>% dplyr::select(PATNO, label),
                      benton %>%
                        mutate(PATNO = as.character(PATNO)), by = "PATNO") %>% 
  dplyr::select(PATNO, label, EVENT_ID,all_of(dvs)) %>% 
  pivot_longer(cols = all_of(dvs),
               names_to = "dv",
               values_to= "value",
               values_transform = as.character) %>% 
  mutate(value    = na_if(value, ""),
         value    = na_if(value,"UR"),
         EVENT_ID = na_if(EVENT_ID, "")) %>%
  filter(!is.na(EVENT_ID))

benton$value %>% unique()
  
# Time point sanity check and filtering (selected_period)
benton = benton %>% 
filter(str_detect(EVENT_ID, pattern = paste(c("BL", "V"), collapse = "|"))) %>%
  mutate(EVENT_ID = str_replace_all(string = EVENT_ID, pattern = "V0", replacement = "V"),
         EVENT_ID = ifelse(str_count(EVENT_ID) == 2 & EVENT_ID != "BL", str_replace_all(EVENT_ID, "V", "V0"), EVENT_ID),
         EVENT_ID = as.factor(EVENT_ID)) %>%
  filter(EVENT_ID %in% selected_period) %>% 
  mutate(EVENT_ID = droplevels(EVENT_ID))

# Nesting
benton = benton %>% 
  group_by(dv) %>%
  nest()
 
# Adding information about the dependent variable
y_annotation = codebook$data_dictionary_annotated %>% 
  filter(ITM_NAME %in% unique(benton$dv)) %>% 
  dplyr::select(ITM_NAME, DSCR, ITM_TYPE) %>% 
  rename(dv = ITM_NAME)

benton = left_join(benton, y_annotation, by = "dv") %>% 
  relocate(ITM_TYPE, DSCR, .before = data)
rm(y_annotation)

# 2 Dataframe Sanity check ----
# Check the duplicates and decide what to do (manual) 
benton = benton %>% 
  mutate(n_duplicates     = map(.x = data, .f =~ .x %>% duplicated() %>% sum()),
         patno_duplicates = map(.x = data, .f =~ .x$PATNO[which(duplicated(.x))]),
         data             = map(.x = data, .f =~ .x %>% distinct())) %>% 
  unnest(n_duplicates)

# MVA ----
# Group level (Are there groups that are totally empty regardless the timepoint?)
# if yes  remove useless groups updating data
benton = benton %>% 
  mutate(mva_discard_group_data = map(.x = data, .f=~  .x %>% 
                                        distinct() %>% 
                                        group_by(label) %>% 
                                        summarise(n_subjects  = n(),
                                                  n_na        = sum(is.na(value))) %>% 
                                        mutate(na_percentage = round((n_na/n_subjects)*100,2),
                                               discard_group = ifelse(na_percentage >= 90, TRUE, FALSE),
                                               )),
         mva_group_to_discard = map(.x = mva_discard_group_data, .f =~ .x$label[.x$discard_group == TRUE]),
         data                 = map(.x = data, .f = ~ .x %>% 
                      filter(!label %in% unlist(mva_group_to_discard)))) 

# How many subjects with repeated measures?
# Select only them and move on
benton = benton %>% 
  mutate(rm_subjects = map(.x = data, .f =~ .x %>%
                             group_by(PATNO) %>%
                             tally() %>%
                             filter(n == length(selected_period)) %>%
                             .$PATNO),
         data       = map(.x = data, .f =~ .x %>% 
                            filter(PATNO %in% unlist(rm_subjects)))) 

# Verify NA percentage
# in the dataset (dataset missingness)
# in the rows (na_percentage_row_checker)
# remove the na subjects in all timepoints. These subjects  have number  of na > 0
# check how many subjects are left
# Declare if n is sufficient to test
benton = benton %>% 
  mutate(mva_start_dataset_missingness = unlist(map(.x = data, .f =~ round(datasetmissingness(.x)*100,2))),
         mva_na_percentage_row_checker = map(.x = data, .f =~ .x$PATNO[narows_percent(.x) > 0]),
         data                          = map(.x = data, .f =~ .x %>% filter(!PATNO %in% unlist(mva_na_percentage_row_checker))),
         mva_end_dataset_missingness   = unlist(map(.x = data, .f =~ round(datasetmissingness(.x)*100, 2))),
         mva_summary_n_subject         = map(.x = data, .f =~ .x %>% 
                                               group_by(label, EVENT_ID) %>% 
                                               summarise(n = n(),
                                                         is_testable = ifelse(n> 20, TRUE, FALSE),
                                                         .groups = "drop")),
         is_testable                   = map(.x = mva_summary_n_subject, .f= ~ .x$is_testable %>% all()))
# Testing ----
# Correct the class of the data
benton = benton %>% 
  mutate(data = map(.x = data, .f=~ if (ITM_TYPE == "CHAR") { .x %>% 
      mutate(value = as.factor(value))} else {
        .x %>% mutate(value = as.numeric(value))}
      ))

# Check if Char variables are ordinal or binominal
benton = benton %>% 
  mutate(nlev = unlist(map(.x= data, .f = ~ ifelse(ITM_TYPE == "CHAR", .x %>% .$value %>% nlevels(), NA_real_)))) %>% 
  relocate(nlev, .after = DSCR)


benton = benton %>%
  mutate(modeling = map(.x = data, .f = ~ if (is_testable == TRUE & ITM_TYPE == "NUMBER") {numeric_modeling(df = .x,
                                                                                                            gp = gp,
                                                                                                            tp = tp,
                                                                                                            id = id,
                                                                                                            y = y,
                                                                                                            REML = REML)} else if (is_testable == TRUE & ITM_TYPE == "CHAR" & nlev == 2) {binomial_modeling(df = .x, gp = gp, tp = tp, id = id, y = y)} else if(is_testable == TRUE & ITM_TYPE == "CHAR" & nlev > 2) {ordinal_modeling(df = .x, gp = gp, tp = tp, id = id, y = y)
                                                                                                            }
  ))

saveRDS(benton, file = file.path(config$subjectCharacteristics$scexportdir, "benton.rds"))
```

## Cognitive categorization

```{r}
# 1 Data Wrangling ----
# check the value column uniques to see if something strange pops ups and address it in the last mutate
cognitive_categorization = non_motor_assessment$cognitive_categorization
cognitive_categorization = cognitive_categorization %>% dplyr::select(-c("INFODT", "REC_ID", "PAG_NAME", "ORIG_ENTRY", "LAST_UPDATE", "PTCGBOTH"))
dvs           = names(cognitive_categorization)[-c(1,2)]

cognitive_categorization = left_join(core_set %>% dplyr::select(PATNO, label),
                      cognitive_categorization %>%
                        mutate(PATNO = as.character(PATNO)), by = "PATNO") %>% 
  dplyr::select(PATNO, label, EVENT_ID,all_of(dvs)) %>% 
  pivot_longer(cols = all_of(dvs),
               names_to = "dv",
               values_to= "value",
               values_transform = as.character) %>% 
  mutate(value    = na_if(value, ""),
         value    = na_if(value,"UR"),
         value    = na_if(value, "Indeterminate"),
         EVENT_ID = na_if(EVENT_ID, "")) %>%
  filter(!is.na(EVENT_ID))

# CUSTOM REMOVAL OF PRODROMAL: PAY ATTENTION
cognitive_categorization = cognitive_categorization %>% filter(label %in%c("PDC1", "PDC2"))

cognitive_categorization$value %>% unique()
  
# Time point sanity check and filtering (selected_period)
cognitive_categorization = cognitive_categorization %>% 
filter(str_detect(EVENT_ID, pattern = paste(c("BL", "V"), collapse = "|"))) %>%
  mutate(EVENT_ID = str_replace_all(string = EVENT_ID, pattern = "V0", replacement = "V"),
         EVENT_ID = ifelse(str_count(EVENT_ID) == 2 & EVENT_ID != "BL", str_replace_all(EVENT_ID, "V", "V0"), EVENT_ID),
         EVENT_ID = as.factor(EVENT_ID)) %>%
  filter(EVENT_ID %in% selected_period) %>% 
  mutate(EVENT_ID = droplevels(EVENT_ID))

# Nesting
cognitive_categorization = cognitive_categorization %>% 
  group_by(dv) %>%
  nest()
 
# Adding information about the dependent variable
y_annotation = codebook$data_dictionary_annotated %>% 
  filter(ITM_NAME %in% unique(cognitive_categorization$dv)) %>% 
  dplyr::select(ITM_NAME, DSCR, ITM_TYPE) %>% 
  rename(dv = ITM_NAME)

cognitive_categorization = left_join(cognitive_categorization, y_annotation, by = "dv") %>% 
  relocate(ITM_TYPE, DSCR, .before = data)
rm(y_annotation)

# 2 Dataframe Sanity check ----
# Check the duplicates and decide what to do (manual) 
cognitive_categorization = cognitive_categorization %>% 
  mutate(n_duplicates     = map(.x = data, .f =~ .x %>% duplicated() %>% sum()),
         patno_duplicates = map(.x = data, .f =~ .x$PATNO[which(duplicated(.x))]),
         data             = map(.x = data, .f =~ .x %>% distinct())) %>% 
  unnest(n_duplicates)

# MVA ----
# Group level (Are there groups that are totally empty regardless the timepoint?)
# if yes  remove useless groups updating data
cognitive_categorization = cognitive_categorization %>% 
  mutate(mva_discard_group_data = map(.x = data, .f=~  .x %>% 
                                        distinct() %>% 
                                        group_by(label) %>% 
                                        summarise(n_subjects  = n(),
                                                  n_na        = sum(is.na(value))) %>% 
                                        mutate(na_percentage = round((n_na/n_subjects)*100,2),
                                               discard_group = ifelse(na_percentage >= 90, TRUE, FALSE),
                                               )),
         mva_group_to_discard = map(.x = mva_discard_group_data, .f =~ .x$label[.x$discard_group == TRUE]),
         data                 = map(.x = data, .f = ~ .x %>% 
                      filter(!label %in% unlist(mva_group_to_discard)))) 

# How many subjects with repeated measures?
# Select only them and move on
cognitive_categorization = cognitive_categorization %>% 
  mutate(rm_subjects = map(.x = data, .f =~ .x %>%
                             group_by(PATNO) %>%
                             tally() %>%
                             filter(n == length(selected_period)) %>%
                             .$PATNO),
         data       = map(.x = data, .f =~ .x %>% 
                            filter(PATNO %in% unlist(rm_subjects)))) 

# Verify NA percentage
# in the dataset (dataset missingness)
# in the rows (na_percentage_row_checker)
# remove the na subjects in all timepoints. These subjects  have number  of na > 0
# check how many subjects are left
# Declare if n is sufficient to test
cognitive_categorization = cognitive_categorization %>% 
  mutate(mva_start_dataset_missingness = unlist(map(.x = data, .f =~ round(datasetmissingness(.x)*100,2))),
         mva_na_percentage_row_checker = map(.x = data, .f =~ .x$PATNO[narows_percent(.x) > 0]),
         data                          = map(.x = data, .f =~ .x %>% filter(!PATNO %in% unlist(mva_na_percentage_row_checker))),
         mva_end_dataset_missingness   = unlist(map(.x = data, .f =~ round(datasetmissingness(.x)*100, 2))),
         mva_summary_n_subject         = map(.x = data, .f =~ .x %>% 
                                               group_by(label, EVENT_ID) %>% 
                                               summarise(n = n(),
                                                         is_testable = ifelse(n> 20, TRUE, FALSE),
                                                         .groups = "drop")),
         is_testable                   = map(.x = mva_summary_n_subject, .f= ~ .x$is_testable %>% all()))
# Testing ----
# Correct the class of the data
# cognitive_categorization = cognitive_categorization %>%
#   mutate(ITM_TYPE = "CHAR")

cognitive_categorization = cognitive_categorization %>% 
  mutate(data = map(.x = data, .f=~ if (ITM_TYPE == "CHAR") { .x %>% 
      mutate(value = as.factor(value))} else {
        .x %>% mutate(value = as.numeric(value))}
      ))

# Check if Char variables are ordinal or binominal
cognitive_categorization = cognitive_categorization %>% 
  mutate(nlev = unlist(map(.x= data, .f = ~ ifelse(ITM_TYPE == "CHAR", .x %>% .$value %>% nlevels(), NA_real_)))) %>% 
  relocate(nlev, .after = DSCR)


cognitive_categorization = cognitive_categorization %>%
  mutate(modeling = map(.x = data, .f = ~ if (is_testable == TRUE & ITM_TYPE == "NUMBER") {
    try(numeric_modeling(df = .x,
                         gp = gp,
                         tp = tp,
                         id = id,
                         y  = y,
                         REML = REML))
  } else if (is_testable == TRUE & ITM_TYPE == "CHAR" & nlev == 2) {
    try(binomial_modeling(df = .x,
                          gp = gp,
                          tp = tp,
                          id = id,
                          y = y))
  } else if(is_testable == TRUE & ITM_TYPE == "CHAR" & nlev > 2) {
    try(ordinal_modeling(df = .x,
                         gp = gp,
                         tp = tp,
                         id = id,
                         y = y))
    
  }
  ))

saveRDS(cognitive_categorization, file = file.path(config$subjectCharacteristics$scexportdir, "cognitive_categorization.rds"))
```

## Epworth

```{r}
# 1 Data Wrangling ----
# check the value column uniques to see if something strange pops ups and address it in the last mutate
epworth_sleep = non_motor_assessment$epworth_sleepiness_scale
epworth_sleep = epworth_sleep %>% dplyr::select(-c("INFODT", "REC_ID", "PAG_NAME", "ORIG_ENTRY", "LAST_UPDATE", "PTCGBOTH"))
epworth_sleep = epworth_sleep %>% mutate(ESSTOT = rowSums(epworth_sleep[3:ncol(epworth_sleep)]))
dvs           = names(epworth_sleep)[str_detect(names(epworth_sleep), "ESS")]

epworth_sleep = left_join(core_set %>% dplyr::select(PATNO, label),
                      epworth_sleep %>%
                        mutate(PATNO = as.character(PATNO)), by = "PATNO") %>% 
  dplyr::select(PATNO, label, EVENT_ID,all_of(dvs)) %>% 
  pivot_longer(cols = all_of(dvs),
               names_to = "dv",
               values_to= "value",
               values_transform = as.character) %>% 
  mutate(value    = na_if(value, ""),
         value    = na_if(value,"UR"),
         value    = na_if(value, "Indeterminate"),
         EVENT_ID = na_if(EVENT_ID, "")) %>%
  filter(!is.na(EVENT_ID))

# CUSTOM REMOVAL OF PRODROMAL: PAY ATTENTION
epworth_sleep = epworth_sleep %>% filter(label %in%c("PDC1", "PDC2"))

epworth_sleep$value %>% unique()
  

# Time point sanity check and filtering (selected_period)
epworth_sleep = epworth_sleep %>% 
filter(str_detect(EVENT_ID, pattern = paste(c("BL", "V"), collapse = "|"))) %>%
  mutate(EVENT_ID = str_replace_all(string = EVENT_ID, pattern = "V0", replacement = "V"),
         EVENT_ID = ifelse(str_count(EVENT_ID) == 2 & EVENT_ID != "BL", str_replace_all(EVENT_ID, "V", "V0"), EVENT_ID),
         EVENT_ID = as.factor(EVENT_ID)) %>%
  filter(EVENT_ID %in% selected_period) %>% 
  mutate(EVENT_ID = droplevels(EVENT_ID))

# Nesting
epworth_sleep = epworth_sleep %>% 
  group_by(dv) %>%
  nest()
 
# Adding information about the dependent variable
y_annotation = codebook$data_dictionary_annotated %>% 
  filter(ITM_NAME %in% unique(epworth_sleep$dv)) %>% 
  dplyr::select(ITM_NAME, DSCR, ITM_TYPE) %>% 
  rename(dv = ITM_NAME)

epworth_sleep = left_join(epworth_sleep, y_annotation, by = "dv") %>% 
  relocate(ITM_TYPE, DSCR, .before = data)
rm(y_annotation)

# 2 Dataframe Sanity check ----
# Check the duplicates and decide what to do (manual) 
epworth_sleep = epworth_sleep %>% 
  mutate(n_duplicates     = map(.x = data, .f =~ .x %>% duplicated() %>% sum()),
         patno_duplicates = map(.x = data, .f =~ .x$PATNO[which(duplicated(.x))]),
         data             = map(.x = data, .f =~ .x %>% distinct())) %>% 
  unnest(n_duplicates)

# MVA ----
# Group level (Are there groups that are totally empty regardless the timepoint?)
# if yes  remove useless groups updating data
epworth_sleep = epworth_sleep %>% 
  mutate(mva_discard_group_data = map(.x = data, .f=~  .x %>% 
                                        distinct() %>% 
                                        group_by(label) %>% 
                                        summarise(n_subjects  = n(),
                                                  n_na        = sum(is.na(value))) %>% 
                                        mutate(na_percentage = round((n_na/n_subjects)*100,2),
                                               discard_group = ifelse(na_percentage >= 90, TRUE, FALSE),
                                               )),
         mva_group_to_discard = map(.x = mva_discard_group_data, .f =~ .x$label[.x$discard_group == TRUE]),
         data                 = map(.x = data, .f = ~ .x %>% 
                      filter(!label %in% unlist(mva_group_to_discard)))) 

# How many subjects with repeated measures?
# Select only them and move on
epworth_sleep = epworth_sleep %>% 
  mutate(rm_subjects = map(.x = data, .f =~ .x %>%
                             group_by(PATNO) %>%
                             tally() %>%
                             filter(n == length(selected_period)) %>%
                             .$PATNO),
         data       = map(.x = data, .f =~ .x %>% 
                            filter(PATNO %in% unlist(rm_subjects)))) 
#  This check is needed because there are some dataset that are totally empty after rm selection
epworth_sleep = epworth_sleep %>%
  mutate(is_data_empty = map(.x= data, .f = ~ plyr::empty(.x) )) %>%
  filter(is_data_empty == FALSE)

# Verify NA percentage
# in the dataset (dataset missingness)
# in the rows (na_percentage_row_checker)
# remove the na subjects in all timepoints. These subjects  have number  of na > 0
# check how many subjects are left
# Declare if n is sufficient to test
epworth_sleep = epworth_sleep %>% 
  mutate(mva_start_dataset_missingness = unlist(map(.x = data, .f =~ round(datasetmissingness(.x)*100,2))),
         mva_na_percentage_row_checker = map(.x = data, .f =~ .x$PATNO[narows_percent(.x) > 0]),
         data                          = map(.x = data, .f =~ .x %>% filter(!PATNO %in% unlist(mva_na_percentage_row_checker))),
         mva_end_dataset_missingness   = unlist(map(.x = data, .f =~ round(datasetmissingness(.x)*100, 2))),
         mva_summary_n_subject         = map(.x = data, .f =~ .x %>% 
                                               group_by(label, EVENT_ID) %>% 
                                               summarise(n = n(),
                                                         is_testable = ifelse(n> 20, TRUE, FALSE),
                                                         .groups = "drop")),
         is_testable                   = map(.x = mva_summary_n_subject, .f= ~ .x$is_testable %>% all()))
# Testing ----
# Correct the class of the data
# epworth_sleep = epworth_sleep %>%
#   mutate(ITM_TYPE = "CHAR")
epworth_sleep$ITM_TYPE[epworth_sleep$dv == "ESSTOT"] = "NUMBER"
epworth_sleep = epworth_sleep %>% 
  mutate(data = map(.x = data, .f=~ if (ITM_TYPE == "CHAR") { .x %>% 
      mutate(value = as.factor(value))} else {
        .x %>% mutate(value = as.numeric(value))}
      ))

# Check if Char variables are ordinal or binominal
epworth_sleep = epworth_sleep %>% 
  mutate(nlev = unlist(map(.x= data, .f = ~ ifelse(ITM_TYPE == "CHAR", .x %>% .$value %>% nlevels(), NA_real_)))) %>% 
  relocate(nlev, .after = DSCR)


epworth_sleep = epworth_sleep %>%
  mutate(modeling = map(.x = data, .f = ~ if (is_testable == TRUE & ITM_TYPE == "NUMBER") {
    try(numeric_modeling(df = .x,
                         gp = gp,
                         tp = tp,
                         id = id,
                         y  = y,
                         REML = REML))
  } else if (is_testable == TRUE & ITM_TYPE == "CHAR" & nlev == 2) {
    try(binomial_modeling(df = .x,
                          gp = gp,
                          tp = tp,
                          id = id,
                          y = y))
  } else if(is_testable == TRUE & ITM_TYPE == "CHAR" & nlev > 2) {
    try(ordinal_modeling(df = .x,
                         gp = gp,
                         tp = tp,
                         id = id,
                         y = y))
    
  }
  ))

saveRDS(epworth_sleep, file = file.path(config$subjectCharacteristics$scexportdir, "epworth_sleep.rds"))
```

## Depression

```{r}
# 1 Data Wrangling ----
# check the value column uniques to see if something strange pops ups and address it in the last mutate
geriatric_depression = non_motor_assessment$geriatric_depression_scale__short_version_
geriatric_depression = geriatric_depression %>% dplyr::select(-c("INFODT", "REC_ID", "PAG_NAME", "ORIG_ENTRY", "LAST_UPDATE"))
geriatric_depression = geriatric_depression %>% mutate(GDSTOT = rowSums(geriatric_depression[3:ncol(geriatric_depression)]))
dvs           = names(geriatric_depression)[str_detect(names(geriatric_depression), "GDS")]

geriatric_depression = left_join(core_set %>% dplyr::select(PATNO, label),
                      geriatric_depression %>%
                        mutate(PATNO = as.character(PATNO)), by = "PATNO") %>% 
  dplyr::select(PATNO, label, EVENT_ID,all_of(dvs)) %>% 
  pivot_longer(cols = all_of(dvs),
               names_to = "dv",
               values_to= "value",
               values_transform = as.character) %>% 
  mutate(value    = na_if(value, ""),
         value    = na_if(value,"UR"),
         value    = na_if(value, "Indeterminate"),
         EVENT_ID = na_if(EVENT_ID, "")) %>%
  filter(!is.na(EVENT_ID))

# CUSTOM REMOVAL OF PRODROMAL: PAY ATTENTION
# geriatric_depression = geriatric_depression %>% filter(label %in%c("PDC1", "PDC2"))

geriatric_depression$value %>% unique()
  

# Time point sanity check and filtering (selected_period)
geriatric_depression = geriatric_depression %>% 
filter(str_detect(EVENT_ID, pattern = paste(c("BL", "V"), collapse = "|"))) %>%
  mutate(EVENT_ID = str_replace_all(string = EVENT_ID, pattern = "V0", replacement = "V"),
         EVENT_ID = ifelse(str_count(EVENT_ID) == 2 & EVENT_ID != "BL", str_replace_all(EVENT_ID, "V", "V0"), EVENT_ID),
         EVENT_ID = as.factor(EVENT_ID)) %>%
  filter(EVENT_ID %in% selected_period) %>% 
  mutate(EVENT_ID = droplevels(EVENT_ID))

# Nesting
geriatric_depression = geriatric_depression %>% 
  group_by(dv) %>%
  nest()
 
# Adding information about the dependent variable
y_annotation = codebook$data_dictionary_annotated %>% 
  filter(ITM_NAME %in% unique(geriatric_depression$dv)) %>% 
  dplyr::select(ITM_NAME, DSCR, ITM_TYPE) %>% 
  rename(dv = ITM_NAME)

geriatric_depression = left_join(geriatric_depression, y_annotation, by = "dv") %>% 
  relocate(ITM_TYPE, DSCR, .before = data)
rm(y_annotation)

# 2 Dataframe Sanity check ----
# Check the duplicates and decide what to do (manual) 
geriatric_depression = geriatric_depression %>% 
  mutate(n_duplicates     = map(.x = data, .f =~ .x %>% duplicated() %>% sum()),
         patno_duplicates = map(.x = data, .f =~ .x$PATNO[which(duplicated(.x))]),
         data             = map(.x = data, .f =~ .x %>% distinct())) %>% 
  unnest(n_duplicates)

# MVA ----
# Group level (Are there groups that are totally empty regardless the timepoint?)
# if yes  remove useless groups updating data
geriatric_depression = geriatric_depression %>% 
  mutate(mva_discard_group_data = map(.x = data, .f=~  .x %>% 
                                        distinct() %>% 
                                        group_by(label) %>% 
                                        summarise(n_subjects  = n(),
                                                  n_na        = sum(is.na(value))) %>% 
                                        mutate(na_percentage = round((n_na/n_subjects)*100,2),
                                               discard_group = ifelse(na_percentage >= 90, TRUE, FALSE),
                                               )),
         mva_group_to_discard = map(.x = mva_discard_group_data, .f =~ .x$label[.x$discard_group == TRUE]),
         data                 = map(.x = data, .f = ~ .x %>% 
                      filter(!label %in% unlist(mva_group_to_discard)))) 

# How many subjects with repeated measures?
# Select only them and move on
geriatric_depression = geriatric_depression %>% 
  mutate(rm_subjects = map(.x = data, .f =~ .x %>%
                             group_by(PATNO) %>%
                             tally() %>%
                             filter(n == length(selected_period)) %>%
                             .$PATNO),
         data       = map(.x = data, .f =~ .x %>% 
                            filter(PATNO %in% unlist(rm_subjects)))) 
#  This check is needed because there are some dataset that are totally empty after rm selection
geriatric_depression = geriatric_depression %>%
  mutate(is_data_empty = map(.x= data, .f = ~ plyr::empty(.x) )) %>%
  filter(is_data_empty == FALSE)

# Verify NA percentage
# in the dataset (dataset missingness)
# in the rows (na_percentage_row_checker)
# remove the na subjects in all timepoints. These subjects  have number  of na > 0
# check how many subjects are left
# Declare if n is sufficient to test
geriatric_depression = geriatric_depression %>% 
  mutate(mva_start_dataset_missingness = unlist(map(.x = data, .f =~ round(datasetmissingness(.x)*100,2))),
         mva_na_percentage_row_checker = map(.x = data, .f =~ .x$PATNO[narows_percent(.x) > 0]),
         data                          = map(.x = data, .f =~ .x %>% filter(!PATNO %in% unlist(mva_na_percentage_row_checker))),
         mva_end_dataset_missingness   = unlist(map(.x = data, .f =~ round(datasetmissingness(.x)*100, 2))),
         mva_summary_n_subject         = map(.x = data, .f =~ .x %>% 
                                               group_by(label, EVENT_ID) %>% 
                                               summarise(n = n(),
                                                         is_testable = ifelse(n> 20, TRUE, FALSE),
                                                         .groups = "drop")),
         is_testable                   = map(.x = mva_summary_n_subject, .f= ~ .x$is_testable %>% all()))
# Testing ----
# Correct the class of the data
# geriatric_depression = geriatric_depression %>%
#   mutate(ITM_TYPE = "CHAR")
geriatric_depression$ITM_TYPE[geriatric_depression$dv == "GDSTOT"] = "NUMBER"
geriatric_depression = geriatric_depression %>% 
  mutate(data = map(.x = data, .f=~ if (ITM_TYPE == "CHAR") { .x %>% 
      mutate(value = as.factor(value))} else {
        .x %>% mutate(value = as.numeric(value))}
      ))

# Check if Char variables are ordinal or binominal
geriatric_depression = geriatric_depression %>% 
  mutate(nlev = unlist(map(.x= data, .f = ~ ifelse(ITM_TYPE == "CHAR", .x %>% .$value %>% nlevels(), NA_real_)))) %>% 
  relocate(nlev, .after = DSCR)


geriatric_depression = geriatric_depression %>%
  mutate(modeling = map(.x = data, .f = ~ if (is_testable == TRUE & ITM_TYPE == "NUMBER") {
    try(numeric_modeling(df = .x,
                         gp = gp,
                         tp = tp,
                         id = id,
                         y  = y,
                         REML = REML))
  } else if (is_testable == TRUE & ITM_TYPE == "CHAR" & nlev == 2) {
    try(binomial_modeling(df = .x,
                          gp = gp,
                          tp = tp,
                          id = id,
                          y = y))
  } else if(is_testable == TRUE & ITM_TYPE == "CHAR" & nlev > 2) {
    try(ordinal_modeling(df = .x,
                         gp = gp,
                         tp = tp,
                         id = id,
                         y = y))
    
  }
  ))

saveRDS(geriatric_depression, file = file.path(config$subjectCharacteristics$scexportdir, "geriatric_depression.rds"))
```

## Verbal learning

```{r}
# 1 Data Wrangling ----
# check the value column uniques to see if something strange pops ups and address it in the last mutate
verbal_learning = non_motor_assessment$hopkins_verbal_learning_test_._revised
verbal_learning = verbal_learning %>% dplyr::select(-c("INFODT", "REC_ID", "PAG_NAME", "ORIG_ENTRY", "LAST_UPDATE"))
#verbal_learning = verbal_learning %>% mutate(GDSTOT = rowSums(verbal_learning[3:ncol(verbal_learning)]))
dvs           = names(verbal_learning)[str_detect(names(verbal_learning), "DVT")]

verbal_learning = left_join(core_set %>% dplyr::select(PATNO, label),
                      verbal_learning %>%
                        mutate(PATNO = as.character(PATNO)), by = "PATNO") %>% 
  dplyr::select(PATNO, label, EVENT_ID,all_of(dvs)) %>% 
  pivot_longer(cols = all_of(dvs),
               names_to = "dv",
               values_to= "value",
               values_transform = as.character) %>% 
  mutate(value    = na_if(value, ""),
         value    = na_if(value,"UR"),
         value    = na_if(value, "Indeterminate"),
         EVENT_ID = na_if(EVENT_ID, "")) %>%
  filter(!is.na(EVENT_ID))

# CUSTOM REMOVAL OF PRODROMAL: PAY ATTENTION
# verbal_learning = verbal_learning %>% filter(label %in%c("PDC1", "PDC2"))

verbal_learning$value %>% unique()
  

# Time point sanity check and filtering (selected_period)
verbal_learning = verbal_learning %>% 
filter(str_detect(EVENT_ID, pattern = paste(c("BL", "V"), collapse = "|"))) %>%
  mutate(EVENT_ID = str_replace_all(string = EVENT_ID, pattern = "V0", replacement = "V"),
         EVENT_ID = ifelse(str_count(EVENT_ID) == 2 & EVENT_ID != "BL", str_replace_all(EVENT_ID, "V", "V0"), EVENT_ID),
         EVENT_ID = as.factor(EVENT_ID)) %>%
  filter(EVENT_ID %in% selected_period) %>% 
  mutate(EVENT_ID = droplevels(EVENT_ID))

# Nesting
verbal_learning = verbal_learning %>% 
  group_by(dv) %>%
  nest()
 
# Adding information about the dependent variable
y_annotation = codebook$data_dictionary_annotated %>% 
  filter(ITM_NAME %in% unique(verbal_learning$dv)) %>% 
  dplyr::select(ITM_NAME, DSCR, ITM_TYPE) %>% 
  rename(dv = ITM_NAME)

verbal_learning = left_join(verbal_learning, y_annotation, by = "dv") %>% 
  relocate(ITM_TYPE, DSCR, .before = data)
rm(y_annotation)

# 2 Dataframe Sanity check ----
# Check the duplicates and decide what to do (manual) 
verbal_learning = verbal_learning %>% 
  mutate(n_duplicates     = map(.x = data, .f =~ .x %>% duplicated() %>% sum()),
         patno_duplicates = map(.x = data, .f =~ .x$PATNO[which(duplicated(.x))]),
         data             = map(.x = data, .f =~ .x %>% distinct())) %>% 
  unnest(n_duplicates)

# MVA ----
# Group level (Are there groups that are totally empty regardless the timepoint?)
# if yes  remove useless groups updating data
verbal_learning = verbal_learning %>% 
  mutate(mva_discard_group_data = map(.x = data, .f=~  .x %>% 
                                        distinct() %>% 
                                        group_by(label) %>% 
                                        summarise(n_subjects  = n(),
                                                  n_na        = sum(is.na(value))) %>% 
                                        mutate(na_percentage = round((n_na/n_subjects)*100,2),
                                               discard_group = ifelse(na_percentage >= 90, TRUE, FALSE),
                                               )),
         mva_group_to_discard = map(.x = mva_discard_group_data, .f =~ .x$label[.x$discard_group == TRUE]),
         data                 = map(.x = data, .f = ~ .x %>% 
                      filter(!label %in% unlist(mva_group_to_discard)))) 

# How many subjects with repeated measures?
# Select only them and move on
verbal_learning = verbal_learning %>% 
  mutate(rm_subjects = map(.x = data, .f =~ .x %>%
                             group_by(PATNO) %>%
                             tally() %>%
                             filter(n == length(selected_period)) %>%
                             .$PATNO),
         data       = map(.x = data, .f =~ .x %>% 
                            filter(PATNO %in% unlist(rm_subjects)))) 
#  This check is needed because there are some dataset that are totally empty after rm selection
verbal_learning = verbal_learning %>%
  mutate(is_data_empty = map(.x= data, .f = ~ plyr::empty(.x) )) %>%
  filter(is_data_empty == FALSE)

# Verify NA percentage
# in the dataset (dataset missingness)
# in the rows (na_percentage_row_checker)
# remove the na subjects in all timepoints. These subjects  have number  of na > 0
# check how many subjects are left
# Declare if n is sufficient to test
verbal_learning = verbal_learning %>% 
  mutate(mva_start_dataset_missingness = unlist(map(.x = data, .f =~ round(datasetmissingness(.x)*100,2))),
         mva_na_percentage_row_checker = map(.x = data, .f =~ .x$PATNO[narows_percent(.x) > 0]),
         data                          = map(.x = data, .f =~ .x %>% filter(!PATNO %in% unlist(mva_na_percentage_row_checker))),
         mva_end_dataset_missingness   = unlist(map(.x = data, .f =~ round(datasetmissingness(.x)*100, 2))),
         mva_summary_n_subject         = map(.x = data, .f =~ .x %>% 
                                               group_by(label, EVENT_ID) %>% 
                                               summarise(n = n(),
                                                         is_testable = ifelse(n> 20, TRUE, FALSE),
                                                         .groups = "drop")),
         is_testable                   = map(.x = mva_summary_n_subject, .f= ~ .x$is_testable %>% all()))
# Testing ----
# Correct the class of the data
# verbal_learning = verbal_learning %>%
#   mutate(ITM_TYPE = "CHAR")
#verbal_learning$ITM_TYPE[verbal_learning$dv == "GDSTOT"] = "NUMBER"
verbal_learning = verbal_learning %>% 
  mutate(data = map(.x = data, .f=~ if (ITM_TYPE == "CHAR") { .x %>% 
      mutate(value = as.factor(value))} else {
        .x %>% mutate(value = as.numeric(value))}
      ))

# Check if Char variables are ordinal or binominal
verbal_learning = verbal_learning %>% 
  mutate(nlev = unlist(map(.x= data, .f = ~ ifelse(ITM_TYPE == "CHAR", .x %>% .$value %>% nlevels(), NA_real_)))) %>% 
  relocate(nlev, .after = DSCR)


verbal_learning = verbal_learning %>%
  mutate(modeling = map(.x = data, .f = ~ if (is_testable == TRUE & ITM_TYPE == "NUMBER") {
    try(numeric_modeling(df = .x,
                         gp = gp,
                         tp = tp,
                         id = id,
                         y  = y,
                         REML = REML))
  } else if (is_testable == TRUE & ITM_TYPE == "CHAR" & nlev == 2) {
    try(binomial_modeling(df = .x,
                          gp = gp,
                          tp = tp,
                          id = id,
                          y = y))
  } else if(is_testable == TRUE & ITM_TYPE == "CHAR" & nlev > 2) {
    try(ordinal_modeling(df = .x,
                         gp = gp,
                         tp = tp,
                         id = id,
                         y = y))
    
  }
  ))

saveRDS(verbal_learning, file = file.path(config$subjectCharacteristics$scexportdir, "verbal_learning.rds"))
```

## letter Number

```{r}
# 1 Data Wrangling ----
# check the value column uniques to see if something strange pops ups and address it in the last mutate
letter_number_seq = non_motor_assessment$letter_._number_sequencing
letter_number_seq = letter_number_seq %>% dplyr::select(-c("INFODT", "REC_ID", "PAG_NAME", "ORIG_ENTRY", "LAST_UPDATE"))
#letter_number_seq = letter_number_seq %>% mutate(GDSTOT = rowSums(letter_number_seq[3:ncol(letter_number_seq)]))
#dvs           = names(letter_number_seq)[str_detect(names(letter_number_seq), "DVT")]
dvs           = c("LNS_TOTRAW", "AGE_ASSESS_LNS", "DVS_LNS")

letter_number_seq = left_join(core_set %>% dplyr::select(PATNO, label),
                      letter_number_seq %>%
                        mutate(PATNO = as.character(PATNO)), by = "PATNO") %>% 
  dplyr::select(PATNO, label, EVENT_ID,all_of(dvs)) %>% 
  pivot_longer(cols = all_of(dvs),
               names_to = "dv",
               values_to= "value",
               values_transform = as.character) %>% 
  mutate(value    = na_if(value, ""),
         value    = na_if(value,"UR"),
         value    = na_if(value, "Indeterminate"),
         EVENT_ID = na_if(EVENT_ID, "")) %>%
  filter(!is.na(EVENT_ID))

# CUSTOM REMOVAL OF PRODROMAL: PAY ATTENTION
# letter_number_seq = letter_number_seq %>% filter(label %in%c("PDC1", "PDC2"))

letter_number_seq$value %>% unique()
  

# Time point sanity check and filtering (selected_period)
letter_number_seq = letter_number_seq %>% 
filter(str_detect(EVENT_ID, pattern = paste(c("BL", "V"), collapse = "|"))) %>%
  mutate(EVENT_ID = str_replace_all(string = EVENT_ID, pattern = "V0", replacement = "V"),
         EVENT_ID = ifelse(str_count(EVENT_ID) == 2 & EVENT_ID != "BL", str_replace_all(EVENT_ID, "V", "V0"), EVENT_ID),
         EVENT_ID = as.factor(EVENT_ID)) %>%
  filter(EVENT_ID %in% selected_period) %>% 
  mutate(EVENT_ID = droplevels(EVENT_ID))

# Nesting
letter_number_seq = letter_number_seq %>% 
  group_by(dv) %>%
  nest()
 
# Adding information about the dependent variable
y_annotation = codebook$data_dictionary_annotated %>% 
  filter(ITM_NAME %in% unique(letter_number_seq$dv)) %>% 
  dplyr::select(ITM_NAME, DSCR, ITM_TYPE) %>% 
  rename(dv = ITM_NAME)

letter_number_seq = left_join(letter_number_seq, y_annotation, by = "dv") %>% 
  relocate(ITM_TYPE, DSCR, .before = data)
rm(y_annotation)

# 2 Dataframe Sanity check ----
# Check the duplicates and decide what to do (manual) 
letter_number_seq = letter_number_seq %>% 
  mutate(n_duplicates     = map(.x = data, .f =~ .x %>% duplicated() %>% sum()),
         patno_duplicates = map(.x = data, .f =~ .x$PATNO[which(duplicated(.x))]),
         data             = map(.x = data, .f =~ .x %>% distinct())) %>% 
  unnest(n_duplicates)

# MVA ----
# Group level (Are there groups that are totally empty regardless the timepoint?)
# if yes  remove useless groups updating data
letter_number_seq = letter_number_seq %>% 
  mutate(mva_discard_group_data = map(.x = data, .f=~  .x %>% 
                                        distinct() %>% 
                                        group_by(label) %>% 
                                        summarise(n_subjects  = n(),
                                                  n_na        = sum(is.na(value))) %>% 
                                        mutate(na_percentage = round((n_na/n_subjects)*100,2),
                                               discard_group = ifelse(na_percentage >= 90, TRUE, FALSE),
                                               )),
         mva_group_to_discard = map(.x = mva_discard_group_data, .f =~ .x$label[.x$discard_group == TRUE]),
         data                 = map(.x = data, .f = ~ .x %>% 
                      filter(!label %in% unlist(mva_group_to_discard)))) 

# How many subjects with repeated measures?
# Select only them and move on
letter_number_seq = letter_number_seq %>% 
  mutate(rm_subjects = map(.x = data, .f =~ .x %>%
                             group_by(PATNO) %>%
                             tally() %>%
                             filter(n == length(selected_period)) %>%
                             .$PATNO),
         data       = map(.x = data, .f =~ .x %>% 
                            filter(PATNO %in% unlist(rm_subjects)))) 
#  This check is needed because there are some dataset that are totally empty after rm selection
letter_number_seq = letter_number_seq %>%
  mutate(is_data_empty = map(.x= data, .f = ~ plyr::empty(.x) )) %>%
  filter(is_data_empty == FALSE)

# Verify NA percentage
# in the dataset (dataset missingness)
# in the rows (na_percentage_row_checker)
# remove the na subjects in all timepoints. These subjects  have number  of na > 0
# check how many subjects are left
# Declare if n is sufficient to test
letter_number_seq = letter_number_seq %>% 
  mutate(mva_start_dataset_missingness = unlist(map(.x = data, .f =~ round(datasetmissingness(.x)*100,2))),
         mva_na_percentage_row_checker = map(.x = data, .f =~ .x$PATNO[narows_percent(.x) > 0]),
         data                          = map(.x = data, .f =~ .x %>% filter(!PATNO %in% unlist(mva_na_percentage_row_checker))),
         mva_end_dataset_missingness   = unlist(map(.x = data, .f =~ round(datasetmissingness(.x)*100, 2))),
         mva_summary_n_subject         = map(.x = data, .f =~ .x %>% 
                                               group_by(label, EVENT_ID) %>% 
                                               summarise(n = n(),
                                                         is_testable = ifelse(n> 20, TRUE, FALSE),
                                                         .groups = "drop")),
         is_testable                   = map(.x = mva_summary_n_subject, .f= ~ .x$is_testable %>% all()))
# Testing ----
# Correct the class of the data
# letter_number_seq = letter_number_seq %>%
#   mutate(ITM_TYPE = "CHAR")
#letter_number_seq$ITM_TYPE[letter_number_seq$dv == "GDSTOT"] = "NUMBER"
letter_number_seq = letter_number_seq %>% 
  mutate(data = map(.x = data, .f=~ if (ITM_TYPE == "CHAR") { .x %>% 
      mutate(value = as.factor(value))} else {
        .x %>% mutate(value = as.numeric(value))}
      ))

# Check if Char variables are ordinal or binominal
letter_number_seq = letter_number_seq %>% 
  mutate(nlev = unlist(map(.x= data, .f = ~ ifelse(ITM_TYPE == "CHAR", .x %>% .$value %>% nlevels(), NA_real_)))) %>% 
  relocate(nlev, .after = DSCR)


letter_number_seq = letter_number_seq %>%
  mutate(modeling = map(.x = data, .f = ~ if (is_testable == TRUE & ITM_TYPE == "NUMBER") {
    try(numeric_modeling(df = .x,
                         gp = gp,
                         tp = tp,
                         id = id,
                         y  = y,
                         REML = REML))
  } else if (is_testable == TRUE & ITM_TYPE == "CHAR" & nlev == 2) {
    try(binomial_modeling(df = .x,
                          gp = gp,
                          tp = tp,
                          id = id,
                          y = y))
  } else if(is_testable == TRUE & ITM_TYPE == "CHAR" & nlev > 2) {
    try(ordinal_modeling(df = .x,
                         gp = gp,
                         tp = tp,
                         id = id,
                         y = y))
    
  }
  ))

saveRDS(letter_number_seq, file = file.path(config$subjectCharacteristics$scexportdir, "letter_number_seq.rds"))
```

## lexical fluency

```{r}
# 1 Data Wrangling ----
# check the value column uniques to see if something strange pops ups and address it in the last mutate
lexical_fluency = non_motor_assessment$lexical_fluency
lexical_fluency = lexical_fluency %>% dplyr::select(-c("INFODT", "REC_ID", "PAG_NAME", "ORIG_ENTRY", "LAST_UPDATE"))
lexical_fluency = lexical_fluency %>% mutate(LXTOT = rowSums(lexical_fluency[3:ncol(lexical_fluency)]))
dvs             = names(lexical_fluency)[str_detect(names(lexical_fluency), "LX")]

lexical_fluency = first_wrangler(data = lexical_fluency, custom_gp_removal = TRUE)
lexical_fluency$value %>% unique()
lexical_fluency = second_wrangler(data = lexical_fluency)

# Testing ----
# Correct the class of the data
# lexical_fluency = lexical_fluency %>% mutate(ITM_TYPE = "CHAR")
lexical_fluency$ITM_TYPE[lexical_fluency$dv == "LXTOT"] = "NUMBER"

lexical_fluency = third_tester(data = lexical_fluency)

saveRDS(lexical_fluency, file = file.path(config$subjectCharacteristics$scexportdir, "lexical_fluency.rds"))
```

## Boston Naming

```{r}
# 1 Data Wrangling ----
# check the value column uniques to see if something strange pops ups and address it in the last mutate
boston_naming = non_motor_assessment$modified_boston_naming_test
boston_naming = boston_naming %>% dplyr::select(-c("INFODT", "REC_ID", "PAG_NAME", "ORIG_ENTRY", "LAST_UPDATE"))
#boston_naming = boston_naming %>% mutate(LXTOT = rowSums(boston_naming[3:ncol(boston_naming)]))
dvs             = names(boston_naming)[str_detect(names(boston_naming), "MBS")]

boston_naming = first_wrangler(data = boston_naming, custom_gp_removal = TRUE)
boston_naming$value %>% unique()
boston_naming = second_wrangler(data = boston_naming)

# Testing ----
# Correct the class of the data
# boston_naming = boston_naming %>% mutate(ITM_TYPE = "CHAR")
boston_naming$ITM_TYPE[boston_naming$dv == "LXTOT"] = "NUMBER"

boston_naming = third_tester(data = boston_naming)

saveRDS(boston_naming, file = file.path(config$subjectCharacteristics$scexportdir, "boston_naming.rds"))
```
## semantic fluency

```{r}
# 1 Data Wrangling ----
# check the value column uniques to see if something strange pops ups and address it in the last mutate
semantic_fluency = non_motor_assessment$modified_semantic_fluency
semantic_fluency = semantic_fluency %>% dplyr::select(-c("INFODT", "REC_ID", "PAG_NAME", "ORIG_ENTRY", "LAST_UPDATE"))
#semantic_fluency = semantic_fluency %>% mutate(LXTOT = rowSums(semantic_fluency[3:ncol(semantic_fluency)]))
# dvs             = names(semantic_fluency)[str_detect(names(semantic_fluency), "MBS")]
dvs             = names(semantic_fluency)[3:ncol(semantic_fluency)]

semantic_fluency = first_wrangler(data = semantic_fluency, custom_gp_removal = TRUE)
semantic_fluency$value %>% unique()
semantic_fluency = second_wrangler(data = semantic_fluency)

# Testing ----
# Correct the class of the data
# semantic_fluency = semantic_fluency %>% mutate(ITM_TYPE = "CHAR")
# semantic_fluency$ITM_TYPE[semantic_fluency$dv == "LXTOT"] = "NUMBER"

semantic_fluency = third_tester(data = semantic_fluency)

saveRDS(semantic_fluency, file = file.path(config$subjectCharacteristics$scexportdir, "semantic_fluency.rds"))
```

## MOCA

```{r}
# 1 Data Wrangling ----
# check the value column uniques to see if something strange pops ups and address it in the last mutate
moca = non_motor_assessment$montreal_cognitive_assessment__moca_
moca = moca %>% dplyr::select(-c("INFODT", "REC_ID", "PAG_NAME", "ORIG_ENTRY", "LAST_UPDATE"))
#moca = moca %>% mutate(LXTOT = rowSums(moca[3:ncol(moca)]))
# dvs             = names(moca)[str_detect(names(moca), "MBS")]
dvs             = names(moca)[3:ncol(moca)]

moca = first_wrangler(data = moca, custom_gp_removal = TRUE)
moca$value %>% unique()
moca = second_wrangler(data = moca)

# Testing ----
# Correct the class of the data
# moca = moca %>% mutate(ITM_TYPE = "CHAR")
# moca$ITM_TYPE[moca$dv == "LXTOT"] = "NUMBER"

moca = third_tester(data = moca)

saveRDS(moca, file = file.path(config$subjectCharacteristics$scexportdir, "moca.rds"))
```
## NQL COGNITION FUNCTION

```{r}
# 1 Data Wrangling ----
# check the value column uniques to see if something strange pops ups and address it in the last mutate
neuro_qol_cognition_function = non_motor_assessment$neuro_qol__cognition_function_._short_form
neuro_qol_cognition_function = neuro_qol_cognition_function %>% dplyr::select(-c("INFODT", "REC_ID", "PAG_NAME", "ORIG_ENTRY", "LAST_UPDATE"))
#neuro_qol_cognition_function = neuro_qol_cognition_function %>% mutate(LXTOT = rowSums(neuro_qol_cognition_function[3:ncol(neuro_qol_cognition_function)]))
# dvs             = names(neuro_qol_cognition_function)[str_detect(names(neuro_qol_cognition_function), "MBS")]
dvs             = names(neuro_qol_cognition_function)[3:ncol(neuro_qol_cognition_function)]

neuro_qol_cognition_function = first_wrangler(data = neuro_qol_cognition_function, custom_gp_removal = TRUE)
neuro_qol_cognition_function$value %>% unique()
neuro_qol_cognition_function = second_wrangler(data = neuro_qol_cognition_function)

# Testing ----
# Correct the class of the data
# neuro_qol_cognition_function = neuro_qol_cognition_function %>% mutate(ITM_TYPE = "CHAR")
# neuro_qol_cognition_function$ITM_TYPE[neuro_qol_cognition_function$dv == "LXTOT"] = "NUMBER"

neuro_qol_cognition_function = third_tester(data = neuro_qol_cognition_function)

saveRDS(neuro_qol_cognition_function, file = file.path(config$subjectCharacteristics$scexportdir, "neuro_qol_cognition_function.rds"))
```
## NQL COGNITION FUNCTION

```{r}
# 1 Data Wrangling ----
# check the value column uniques to see if something strange pops ups and address it in the last mutate
neuro_qol_communication = non_motor_assessment$neuro_qol__communication_._short_form
neuro_qol_communication = neuro_qol_communication %>% dplyr::select(-c("INFODT", "REC_ID", "PAG_NAME", "ORIG_ENTRY", "LAST_UPDATE"))
#neuro_qol_communication = neuro_qol_communication %>% mutate(LXTOT = rowSums(neuro_qol_communication[3:ncol(neuro_qol_communication)]))
 dvs             = names(neuro_qol_communication)[str_detect(names(neuro_qol_communication), "NQC")]
# dvs             = names(neuro_qol_communication)[3:ncol(neuro_qol_communication)]

neuro_qol_communication = first_wrangler(data = neuro_qol_communication, custom_gp_removal = TRUE)
neuro_qol_communication$value %>% unique()
neuro_qol_communication = second_wrangler(data = neuro_qol_communication)

# Testing ----
# Correct the class of the data
# neuro_qol_communication = neuro_qol_communication %>% mutate(ITM_TYPE = "CHAR")
# neuro_qol_communication$ITM_TYPE[neuro_qol_communication$dv == "LXTOT"] = "NUMBER"

neuro_qol_communication = third_tester(data = neuro_qol_communication)

saveRDS(neuro_qol_communication, file = file.path(config$subjectCharacteristics$scexportdir, "neuro_qol_communication.rds"))
```
## QUIP

```{r}
# 1 Data Wrangling ----
# check the value column uniques to see if something strange pops ups and address it in the last mutate
quip.current.short = non_motor_assessment$quip.current.short
quip.current.short = quip.current.short %>% dplyr::select(-c("INFODT", "REC_ID", "PAG_NAME", "ORIG_ENTRY", "LAST_UPDATE"))
#quip.current.short = quip.current.short %>% mutate(LXTOT = rowSums(quip.current.short[3:ncol(quip.current.short)]))
# dvs             = names(quip.current.short)[str_detect(names(quip.current.short), "NQC")]
dvs             = names(quip.current.short)[4:ncol(quip.current.short)]

quip.current.short = first_wrangler(data = quip.current.short, custom_gp_removal = FALSE)
quip.current.short$value %>% unique()
quip.current.short = second_wrangler(data = quip.current.short)

# Testing ----
# Correct the class of the data
# quip.current.short = quip.current.short %>% mutate(ITM_TYPE = "CHAR")
# quip.current.short$ITM_TYPE[quip.current.short$dv == "LXTOT"] = "NUMBER"

quip.current.short = third_tester(data = quip.current.short)

saveRDS(quip.current.short, file = file.path(config$subjectCharacteristics$scexportdir, "quip.current.short.rds"))
```
## Rem sleep disorder

```{r}
# 1 Data Wrangling ----
# check the value column uniques to see if something strange pops ups and address it in the last mutate
rem_sleep_disorder = non_motor_assessment$rem_sleep_behavior_disorder_questionnaire
rem_sleep_disorder = rem_sleep_disorder %>% dplyr::select(-c("INFODT", "REC_ID", "PAG_NAME", "ORIG_ENTRY", "LAST_UPDATE"))
rem_sleep_disorder = rem_sleep_disorder %>% mutate(REMTOT = rowSums(rem_sleep_disorder[4:ncol(rem_sleep_disorder)]))
# dvs             = names(rem_sleep_disorder)[str_detect(names(rem_sleep_disorder), "NQC")]
dvs             = names(rem_sleep_disorder)[4:ncol(rem_sleep_disorder)]

rem_sleep_disorder = first_wrangler(data = rem_sleep_disorder, custom_gp_removal = FALSE)
rem_sleep_disorder$value %>% unique()
rem_sleep_disorder = second_wrangler(data = rem_sleep_disorder)

# Testing ----
# Correct the class of the data
rem_sleep_disorder = rem_sleep_disorder %>% mutate(ITM_TYPE = "CHAR")
rem_sleep_disorder$ITM_TYPE[rem_sleep_disorder$dv == "REMTOT"] = "NUMBER"

rem_sleep_disorder = third_tester(data = rem_sleep_disorder)

rem_sleep_disorder = rem_sleep_disorder %>% 
    mutate(data = map(.x = data, .f=~ if (ITM_TYPE == "CHAR") { .x %>% 
        mutate(value = as.factor(value))} else {
          .x %>% mutate(value = as.numeric(value))}
    ))
  
  # Check if Char variables are ordinal or binominal
  rem_sleep_disorder = rem_sleep_disorder %>% 
    mutate(nlev = unlist(map(.x= data, .f = ~ ifelse(ITM_TYPE == "CHAR", .x %>% .$value %>% nlevels(), NA_real_)))) %>% 
    relocate(nlev, .after = DSCR)
  
  
  rem_sleep_disorder = rem_sleep_disorder %>%
    mutate(modeling = map(.x = data, .f = ~ if (is_testable == TRUE & ITM_TYPE == "NUMBER") {
      try(numeric_modeling(df = .x,
                           gp = gp,
                           tp = tp,
                           id = id,
                           y  = y,
                           REML = REML))
    } else if (is_testable == TRUE & ITM_TYPE == "CHAR" & nlev == 2) {
      try(binomial_modeling(df = .x,
                            gp = gp,
                            tp = tp,
                            id = id,
                            y = y))
    } else if(is_testable == TRUE & ITM_TYPE == "CHAR" & nlev > 2) {
      try(ordinal_modeling(df = .x,
                           gp = gp,
                           tp = tp,
                           id = id,
                           y = y))
      
    }
    ))

saveRDS(rem_sleep_disorder, file = file.path(config$subjectCharacteristics$scexportdir, "rem_sleep_disorder.rds"))
```

## SCOPA

```{r}
# 1 Data Wrangling ----
# check the value column uniques to see if something strange pops ups and address it in the last mutate
scopa = non_motor_assessment$scopa.aut
scopa = scopa %>% dplyr::select(-c("INFODT", "REC_ID", "PAG_NAME", "ORIG_ENTRY", "LAST_UPDATE"))
# scopa = scopa %>% mutate(REMTOT = rowSums(scopa[4:ncol(scopa)]))
# dvs             = names(scopa)[str_detect(names(scopa), "NQC")]
dvs             = names(scopa)[4:ncol(scopa)]

scopa = first_wrangler(data = scopa, custom_gp_removal = FALSE)
scopa$value %>% unique()
scopa = second_wrangler(data = scopa)

# Testing ----
# Correct the class of the data
scopa = scopa %>% mutate(ITM_TYPE = "CHAR")
# scopa$ITM_TYPE[scopa$dv == "REMTOT"] = "NUMBER"

scopa = third_tester(data = scopa)

scopa = scopa %>% 
    mutate(data = map(.x = data, .f=~ if (ITM_TYPE == "CHAR") { .x %>% 
        mutate(value = as.factor(value))} else {
          .x %>% mutate(value = as.numeric(value))}
    ))
  
  # Check if Char variables are ordinal or binominal
  scopa = scopa %>% 
    mutate(nlev = unlist(map(.x= data, .f = ~ ifelse(ITM_TYPE == "CHAR", .x %>% .$value %>% nlevels(), NA_real_)))) %>% 
    relocate(nlev, .after = DSCR)
  
  
  scopa = scopa %>%
    mutate(modeling = map(.x = data, .f = ~ if (is_testable == TRUE & ITM_TYPE == "NUMBER") {
      try(numeric_modeling(df = .x,
                           gp = gp,
                           tp = tp,
                           id = id,
                           y  = y,
                           REML = REML))
    } else if (is_testable == TRUE & ITM_TYPE == "CHAR" & nlev == 2) {
      try(binomial_modeling(df = .x,
                            gp = gp,
                            tp = tp,
                            id = id,
                            y = y))
    } else if(is_testable == TRUE & ITM_TYPE == "CHAR" & nlev > 2) {
      try(ordinal_modeling(df = .x,
                           gp = gp,
                           tp = tp,
                           id = id,
                           y = y))
      
    }
    ))

saveRDS(scopa, file = file.path(config$subjectCharacteristics$scexportdir, "scopa.rds"))
```

## Anxiety

```{r}
# 1 Data Wrangling ----
# check the value column uniques to see if something strange pops ups and address it in the last mutate
state_anxiety = non_motor_assessment$state.trait_anxiety_inventory
state_anxiety = state_anxiety %>% dplyr::select(-c("INFODT", "REC_ID", "PAG_NAME", "ORIG_ENTRY", "LAST_UPDATE"))
state_anxiety = state_anxiety %>% mutate(STATOT = rowSums(state_anxiety[4:ncol(state_anxiety)]))
# dvs             = names(state_anxiety)[str_detect(names(state_anxiety), "NQC")]
dvs             = names(state_anxiety)[3:ncol(state_anxiety)]

state_anxiety = first_wrangler(data = state_anxiety, custom_gp_removal = FALSE)
state_anxiety$value %>% unique()
state_anxiety = second_wrangler(data = state_anxiety)

# Testing ----
# Correct the class of the data
state_anxiety = state_anxiety %>% mutate(ITM_TYPE = "CHAR")
state_anxiety$ITM_TYPE[state_anxiety$dv == "STATOT"] = "NUMBER"

state_anxiety = third_tester(data = state_anxiety)


saveRDS(state_anxiety, file = file.path(config$subjectCharacteristics$scexportdir, "state_anxiety.rds"))
```

## Anxiety

```{r}
# 1 Data Wrangling ----
# check the value column uniques to see if something strange pops ups and address it in the last mutate
symbol_digit = non_motor_assessment$symbol_digit_modalities_test
symbol_digit = symbol_digit %>% dplyr::select(-c("INFODT", "REC_ID", "PAG_NAME", "ORIG_ENTRY", "LAST_UPDATE"))
#symbol_digit = symbol_digit %>% mutate(STATOT = rowSums(symbol_digit[4:ncol(symbol_digit)]))
#dvs             = names(symbol_digit)[str_detect(names(symbol_digit), "NQC")]
dvs             = names(symbol_digit)[3:ncol(symbol_digit)]

symbol_digit = first_wrangler(data = symbol_digit, custom_gp_removal = FALSE)
symbol_digit$value %>% unique()
symbol_digit = second_wrangler(data = symbol_digit)

# Testing ----
# Correct the class of the data
#symbol_digit = symbol_digit %>% mutate(ITM_TYPE = "CHAR")
#symbol_digit$ITM_TYPE[symbol_digit$dv == "STATOT"] = "NUMBER"

symbol_digit = third_tester(data = symbol_digit)


saveRDS(symbol_digit, file = file.path(config$subjectCharacteristics$scexportdir, "symbol_digit.rds"))
```

## TRAIL MAKING

```{r}
# 1 Data Wrangling ----
# check the value column uniques to see if something strange pops ups and address it in the last mutate
trail_making_ab = non_motor_assessment$trail_making_a_and_b
trail_making_ab = trail_making_ab %>% dplyr::select(-c("INFODT", "REC_ID", "PAG_NAME", "ORIG_ENTRY", "LAST_UPDATE"))
#trail_making_ab = trail_making_ab %>% mutate(STATOT = rowSums(trail_making_ab[4:ncol(trail_making_ab)]))
#dvs             = names(trail_making_ab)[str_detect(names(trail_making_ab), "NQC")]
dvs             = names(trail_making_ab)[3:ncol(trail_making_ab)]

trail_making_ab = first_wrangler(data = trail_making_ab, custom_gp_removal = FALSE)
trail_making_ab$value %>% unique()
trail_making_ab = second_wrangler(data = trail_making_ab)

# Testing ----
# Correct the class of the data
#trail_making_ab = trail_making_ab %>% mutate(ITM_TYPE = "CHAR")
#trail_making_ab$ITM_TYPE[trail_making_ab$dv == "STATOT"] = "NUMBER"

trail_making_ab = third_tester(data = trail_making_ab)


saveRDS(trail_making_ab, file = file.path(config$subjectCharacteristics$scexportdir, "trail_making_ab.rds"))
```
## SMELL

```{r}
# 1 Data Wrangling ----
# check the value column uniques to see if something strange pops ups and address it in the last mutate
smell = non_motor_assessment$university_of_pennsylvania_smell_identification_test__upsit_
smell = smell %>% dplyr::select(-c("INFODT", "REC_ID", "PAG_NAME", "ORIG_ENTRY", "LAST_UPDATE"))
#smell = smell %>% mutate(SMELLTOT = rowSums(smell[3:ncol(smell)]))
#dvs             = names(smell)[str_detect(names(smell), "NQC")]
dvs             = names(smell)[3:ncol(smell)]

smell = first_wrangler(data = smell, custom_gp_removal = FALSE)
smell$value %>% unique()
smell = second_wrangler(data = smell)

# Testing ----
# Correct the class of the data
#smell = smell %>% mutate(ITM_TYPE = "CHAR")
#smell$ITM_TYPE[smell$dv == "STATOT"] = "NUMBER"

smell = third_tester(data = smell)


saveRDS(smell, file = file.path(config$subjectCharacteristics$scexportdir, "smell.rds"))
```





